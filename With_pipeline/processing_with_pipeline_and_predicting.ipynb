{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing with pipeline \n",
    "\n",
    "## Pipeline Vs make_pipeline:\n",
    "    Pipeline requires naming of steps, make_pipeline does not requires naming of steps.\n",
    "    \n",
    "    (Same applies thing for ColumnTransformer vs make_column_transformer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('t1',\n",
      "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
      "                                   sparse_threshold=0.3,\n",
      "                                   transformer_weights=None,\n",
      "                                   transformers=[('si_age',\n",
      "                                                  SimpleImputer(add_indicator=False,\n",
      "                                                                copy=True,\n",
      "                                                                fill_value=None,\n",
      "                                                                missing_values=nan,\n",
      "                                                                strategy='mean',\n",
      "                                                                verbose=0),\n",
      "                                                  [2]),\n",
      "                                                 ('si_embarked',\n",
      "                                                  SimpleImputer(add_indicator=False,\n",
      "                                                                copy=True,\n",
      "                                                                fill_value=None,\n",
      "                                                                missin...\n",
      "                             score_func=<function chi2 at 0x000001FE1867C0D8>)),\n",
      "                ('t5',\n",
      "                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
      "                                        criterion='gini', max_depth=None,\n",
      "                                        max_features=None, max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        presort='deprecated', random_state=None,\n",
      "                                        splitter='best'))],\n",
      "         verbose=False)\n",
      "********************************************************************************************************\n",
      "ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
      "                  transformer_weights=None,\n",
      "                  transformers=[('si_age',\n",
      "                                 SimpleImputer(add_indicator=False, copy=True,\n",
      "                                               fill_value=None,\n",
      "                                               missing_values=nan,\n",
      "                                               strategy='mean', verbose=0),\n",
      "                                 [2]),\n",
      "                                ('si_embarked',\n",
      "                                 SimpleImputer(add_indicator=False, copy=True,\n",
      "                                               fill_value=None,\n",
      "                                               missing_values=nan,\n",
      "                                               strategy='most_frequent',\n",
      "                                               verbose=0),\n",
      "                                 [6])],\n",
      "                  verbose=False)\n",
      "[30.08266129]\n",
      "********************************************************************************************************\n",
      "{'t1': ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
      "                  transformer_weights=None,\n",
      "                  transformers=[('si_age',\n",
      "                                 SimpleImputer(add_indicator=False, copy=True,\n",
      "                                               fill_value=None,\n",
      "                                               missing_values=nan,\n",
      "                                               strategy='mean', verbose=0),\n",
      "                                 [2]),\n",
      "                                ('si_embarked',\n",
      "                                 SimpleImputer(add_indicator=False, copy=True,\n",
      "                                               fill_value=None,\n",
      "                                               missing_values=nan,\n",
      "                                               strategy='most_frequent',\n",
      "                                               verbose=0),\n",
      "                                 [6])],\n",
      "                  verbose=False), 't2': ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
      "                  transformer_weights=None,\n",
      "                  transformers=[('ohe_sex_embarked',\n",
      "                                 OneHotEncoder(categories='auto', drop=None,\n",
      "                                               dtype=<class 'numpy.float64'>,\n",
      "                                               handle_unknown='ignore',\n",
      "                                               sparse=False),\n",
      "                                 [1, 6])],\n",
      "                  verbose=False), 't3': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
      "                  transformer_weights=None,\n",
      "                  transformers=[('scale',\n",
      "                                 MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
      "                                 slice(0, 10, None))],\n",
      "                  verbose=False), 't4': SelectKBest(k=8, score_func=<function chi2 at 0x000001FE1867C0D8>), 't5': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')}\n",
      "********************************************************************************************************\n",
      "accuraccy :  0.6007462686567164\n",
      "grid.best_score_ : 0.6516516129032258\n",
      "grid.best_params_ :  {'t5__max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Processing with pipeline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "import pickle\n",
    "\n",
    "def read_csv(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data.drop(columns=['PassengerId', 'Name','Ticket', 'Cabin'], inplace=True)\n",
    "    return data\n",
    "\n",
    "def split_data(data):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, Y_train, Y_test =  train_test_split(data.drop(columns=['Survived']),\n",
    "                                                        data['Survived'],\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=1)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "\n",
    "# Applying Simple Imputer on Age and Embarked column\n",
    "def transform_data(X_train,X_test):\n",
    "    # Applying Simple Imputer\n",
    "    t1 = ColumnTransformer([('si_age',SimpleImputer(),[2]),\n",
    "                              ('si_embarked',SimpleImputer(strategy='most_frequent'),[6])\n",
    "                             ],remainder='passthrough')\n",
    "    #remainder='passthrough: means that all columns that are not specified in the list of transformers will be passed through without transformation, instead of being dropped.\n",
    "    \n",
    "    # Applying One hot encoding\n",
    "    t2 = ColumnTransformer([('ohe_sex_embarked',OneHotEncoder(sparse=False,handle_unknown='ignore'),[1,6])\n",
    "                             ],remainder='passthrough')\n",
    "    # handle_unknown='ignore': means that if a column contains an unknown category, it will be ignored during the transformation process.\n",
    "    \n",
    "    # Applying  Scaling\n",
    "    t3 = ColumnTransformer([('scale',MinMaxScaler(),slice(0,10))\n",
    "                             ])\n",
    "    # selecting features\n",
    "    t4 = SelectKBest(score_func=chi2,k=8)\n",
    "    # train the model\n",
    "    t5 = DecisionTreeClassifier()\n",
    "\n",
    "    #Create Pipeline\n",
    "    pipe = Pipeline([('t1',t1),\n",
    "                     ('t2',t2),\n",
    "                     ('t3',t3),\n",
    "                     ('t4',t4),\n",
    "                     ('t5',t5)\n",
    "                    ])\n",
    "    #other way or Alternate Syntax\n",
    "    #pipe = make_pipeline(t1,t2,t3,t4,t5)\n",
    "    \n",
    "    # train\n",
    "    print(pipe.fit(X_train,Y_train))\n",
    "    print(\"********************************************************************************************************\")\n",
    "    \n",
    "    # Code here to see the steps\n",
    "    print(pipe.named_steps['t1'])\n",
    "    print(pipe.named_steps['t1'].transformers_[0][1].statistics_)\n",
    "    print(\"********************************************************************************************************\")\n",
    "    \n",
    "    # Code here to see all the steps\n",
    "    print(pipe.named_steps)\n",
    "    print(\"********************************************************************************************************\")\n",
    "    \n",
    "    \n",
    "    # Predict the result\n",
    "    Y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"accuraccy : \",accuracy_score(Y_test,Y_pred))\n",
    "    \n",
    "    # doing Cross Validation by using Pipeline\n",
    "    # cross validation using cross_val_score\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    cross_val_score(pipe, X_train, Y_train, cv=5, scoring='accuracy').mean()\n",
    "    \n",
    "    # GridSearch using Pipeline\n",
    "    # gridsearchcv\n",
    "    params = {'t5__max_depth':[1,2,3,4,5,None]}\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "    #print(grid.fit(X_train, Y_train))\n",
    "    grid.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"grid.best_score_ :\" ,grid.best_score_)\n",
    "    print(\"grid.best_params_ : \", grid.best_params_ )\n",
    "    \n",
    "    # export the pickle file and saving in pipe_new.pkl file\n",
    "    import pickle\n",
    "    pickle.dump(pipe,open('pipe.pkl','wb'))\n",
    "    \n",
    "    \n",
    "data = read_csv(\"train.csv\")\n",
    "X_train,X_test,Y_train,Y_test = split_data(data)\n",
    "transform_data(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : means survive, 0 : means not survive\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def load_pickle_and_check_result(test_input):\n",
    "    pipe = pickle.load(open('pipe.pkl','rb'))\n",
    "    print(\"1 : means survive, 0 : means not survive\")\n",
    "    print(pipe.predict(test_input))\n",
    "\n",
    "# Let user gave input as\n",
    "#Pclass  Sex   Age  SibSp  Parch    Fare Embarked\n",
    "test_input = np.array([1, 'male', 31.0, 1, 0, 20.5, 'S'],dtype=object).reshape(1,7)\n",
    "load_pickle_and_check_result(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
